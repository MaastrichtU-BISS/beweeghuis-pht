{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2745a08-10c5-457c-9447-ca1660c1b19e",
   "metadata": {},
   "source": [
    "# Federated Logistic Regression training\n",
    "This notebook explains how to perform a federated logistic regression. The first step is to install the required libraries (when necessary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62290ade-8356-4758-b45e-be6cf22da8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install vantage6-client==4.4.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7745d8e8-eb40-42ac-a9c6-fb0802e481c8",
   "metadata": {},
   "source": [
    "## Credentials and login\n",
    "Provide the correct credentials below, to log into a Federated Learning message broker (server). The following variables need to be configured:\n",
    "- `server_url`: the url where the service is running (without port or subfolder specification)\n",
    "- `server_port`: the port number where the server can be reached\n",
    "- `server_api`: the subfolder URL specification needed, default is '/api'\n",
    "- `username`: username of the researcher on the message broker server\n",
    "- `password`: password of the researcher on the message broker server\n",
    "- `organization_key`: if encryption is enabled, the organization key needs to be provided here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c35252-d5fb-4e5a-bd55-db5e694626c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vantage6.client import Client\n",
    "import json, time\n",
    "\n",
    "# Load your configuration settings from a file or environment\n",
    "config = {\n",
    "    'server_url': 'http://host.docker.internal',\n",
    "    'server_port': 5000,\n",
    "    'server_api': '/api',\n",
    "    'username': 'alpha-user',\n",
    "    'password': 'alpha-password',\n",
    "    'organization_key': None\n",
    "}\n",
    "\n",
    "client = Client(config['server_url'], config['server_port'], config['server_api'], log_level='info')\n",
    "client.authenticate(username=config['username'], password=config['password'])\n",
    "client.setup_encryption(config['organization_key'])\n",
    "client.log_level = 'warn'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9549ddba-280d-4e85-b629-9904ec67a7f9",
   "metadata": {},
   "source": [
    "## Define the task to execute\n",
    "Now we are logged into the message broker, we can post a request to execute a specific algorithm. In our case to perform a federated learning execution to calculate a logistic regression.\n",
    "\n",
    "To make this happen, we need to specify some information regarding the algorithm to execute. These are algorithm-specific variables:\n",
    "- `predictors`: The column name which represents the input features for the logistic regression\n",
    "- `outcome`: the column name which represents the label to be predicted\n",
    "- `classes`: options for the output labels to be predicted\n",
    "- `max_iter`: the maximum number of iterations for the algorithm to execute\n",
    "- `delta`: the loss threshold as a separate stopping criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99a13af-eed8-41d2-80cb-65979d623186",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the first collaboration identifier\n",
    "collaboration_id = client.collaboration.list()['data'][0]['id']\n",
    "\n",
    "# Determine the organizations involved in this collaboration\n",
    "organization_ids = [ ]\n",
    "for org in client.organization.list(collaboration=collaboration_id)[\"data\"]:\n",
    "  organization_ids.append(org['id'])\n",
    "\n",
    "# Define algorithm input\n",
    "input_ = {\n",
    "    'method': 'master',\n",
    "    'master': True,\n",
    "    'kwargs': {\n",
    "        'org_ids': organization_ids,          # organisations to run algorithm\n",
    "        'predictors': ['clinical.T.Stage', 'Clinical.N.Stage'], # columns to be used as predictors\n",
    "        'outcome': 'deadstatus.event',       # column to be used as outcome\n",
    "        'classes': [0, 1],          # classes to be predicted\n",
    "        'max_iter': 15,             # maximum number of iterations to perform\n",
    "        'delta': 0.01,              # threshold loss difference for convergence\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3769289-e5b2-4e18-8a0c-e24987cec942",
   "metadata": {},
   "source": [
    "### Execute the task\n",
    "Now we can execute the task itself. Mind the `image` parameter, which refers to a Docker image which will be pulled (=downloaded) at every data station (=node) and executed. The previously defined input is passed in the `input_` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8426b4-5b56-4bac-b990-5ad523d06fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Send the task to the central server\n",
    "task = client.task.create(\n",
    "    collaboration=collaboration_id,\n",
    "    organizations=[client.organization.get()['id']],\n",
    "    name='v6-logistic-regression-py',\n",
    "    image='ghcr.io/maastrichtu-cds/v6-logistic-regression-py:latest',\n",
    "    description='run logistic regression',\n",
    "    databases=[{'label': 'default'}],  # Use your database label\n",
    "    input_=input_,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c04a796-4cd7-4f15-a79d-58cffc56c98a",
   "metadata": {},
   "source": [
    "## Download and interpret results\n",
    "In the following steps, we will download the results, present the parameters of the logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02d55ef-394a-4855-945a-cfcc36c2252f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the results\n",
    "task_info = client.task.get(task['id'], include_results=True)\n",
    "while not task_info['status']=='completed':\n",
    "    print(\"No result (yet) to be retrieved, waiting\")\n",
    "    time.sleep(5)\n",
    "    task_info = client.task.get(task['id'], include_results=True)\n",
    "result = json.loads(client.result.from_task(task['id'])[\"data\"][0][\"result\"])\n",
    "print(json.dumps(result, indent=2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
